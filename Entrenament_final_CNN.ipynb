{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anatorres09/DE-MRI_Classificacio_CNN/blob/main/Entrenament_final_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connectar a Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIkP_r4_hCNF",
        "outputId": "e20ec425-8033-4251-ba5d-5c229d3740df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar llibreries\n",
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from joblib import Parallel, delayed\n",
        "import random"
      ],
      "metadata": {
        "id": "hB1qkfA2hFrV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_folder = '/content/drive/MyDrive/CNN'"
      ],
      "metadata": {
        "id": "zLyQ52AOhGa2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de la carpeta principal\n",
        "ruta_carpeta_normal = os.path.join(drive_folder, \"corr_entrenament\", \"corr_normal\")\n",
        "ruta_carpeta_patologic = os.path.join(drive_folder, \"corr_entrenament\", \"corr_patologic\")"
      ],
      "metadata": {
        "id": "Yl9-CCiKuAUp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redimensionar les imatges a una mida fixa\n",
        "redimensionar_imatge = (128, 128)\n",
        "\n",
        "# Recollir imatges i etiquetes de la carpeta corr_normal\n",
        "def recollir_imatges_etiquetes(ruta_carpeta, etiqueta, redimensionar_imatge):\n",
        "    casos = [nom_carpeta for nom_carpeta in os.listdir(ruta_carpeta) if os.path.isdir(os.path.join(ruta_carpeta, nom_carpeta))]\n",
        "\n",
        "    imatges = []\n",
        "    etiquetes = []\n",
        "\n",
        "    for cas in casos:\n",
        "        ruta_cas = os.path.join(ruta_carpeta, cas)\n",
        "        rutes_imatges = glob(os.path.join(ruta_cas, '*.png'))\n",
        "\n",
        "        for ruta_imatge in rutes_imatges:\n",
        "            imatge = cv2.imread(ruta_imatge)\n",
        "            imatge = cv2.cvtColor(imatge, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Redimensionar les imatges\n",
        "            imatge = cv2.resize(imatge, redimensionar_imatge)\n",
        "            \n",
        "            imatges.append(imatge)\n",
        "            etiquetes.append(etiqueta)\n",
        "\n",
        "    return imatges, etiquetes\n",
        "\n",
        "# Recollir imatges i etiquetes de la carpeta corr_normal\n",
        "imatges_normal, etiquetes_normal = recollir_imatges_etiquetes(ruta_carpeta_normal, \"normal\", redimensionar_imatge)\n",
        "\n",
        "# Recollir imatges i etiquetes de la carpeta corr_patologic\n",
        "imatges_patologic, etiquetes_patologic = recollir_imatges_etiquetes(ruta_carpeta_patologic, \"patologic\", redimensionar_imatge)\n",
        "\n",
        "# Encadenar les llistes d'imatges i etiquetes\n",
        "imatges_total = imatges_normal + imatges_patologic\n",
        "etiquetes_total = etiquetes_normal + etiquetes_patologic\n",
        "\n",
        "# Convertir la llista d'imatges i etiquetes en una matriu numpy\n",
        "matriu_imatges = np.array(imatges_total, dtype='float32')\n",
        "etiquetes = np.array(etiquetes_total)\n",
        "\n",
        "print(f\"S'han recollit {matriu_imatges.shape[0]} imatges en total.\")\n",
        "\n",
        "\n",
        "# Obtenir la quantitat de imatges etiquetades com \"normal\"\n",
        "quantitat_normal = np.count_nonzero(etiquetes == \"normal\")\n",
        "\n",
        "# Obtenir la quntitat de imatges etiquetades com \"patologic\"\n",
        "quantitat_patologic = np.count_nonzero(etiquetes == \"patologic\")\n",
        "\n",
        "print(f\"S'han trobat {quantitat_normal} imatges etiquetades com 'normal'.\")\n",
        "print(f\"S'han trobat {quantitat_patologic} imatges etiquetades com 'patologic'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXDRaCECIE1",
        "outputId": "25d573ff-25ee-48b8-c70b-26e6dcaf3067"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S'han recollit 699 imatges en total.\n",
            "S'han trobat 226 imatges etiquetades com 'normal'.\n",
            "S'han trobat 473 imatges etiquetades com 'patologic'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocessat de les imatges\n",
        "# Normalitzar els valors de píxels al rang [0, 1]\n",
        "#imatges = matriu_imatges/ 255.0\n",
        "\n",
        "# Dividir les dades en conjunts d'entrenament i prova\n",
        "X_train, X_test, y_train, y_test = train_test_split(matriu_imatges, etiquetes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Iniciar LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar i transformar etiquetes\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convertir etiquetes codificades en codificació one-hot\n",
        "y_train = tf.one_hot(y_train_encoded, depth=2)\n",
        "y_test = tf.one_hot(y_test_encoded, depth=2)\n",
        "\n",
        "# Construir el model de la CNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=X_train[0].shape),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el model\n",
        "model.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Crear generadors de dades per l'entrenament i la prova\n",
        "generador_entrenament = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.3, dtype='float16')\n",
        "generador_prova = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.3, dtype='float16')\n",
        "\n",
        "# Crear generadors de fluxe de dades per l'entrenament i la prova\n",
        "flujo_entrenament = generador_entrenament.flow(X_train, y_train, batch_size=32)\n",
        "flujo_prova = generador_prova.flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "\n",
        "# Abans d'entrenar el model\n",
        "gc.collect()  # Alliberar la memòria abans de l'entrenament\n",
        "\n",
        "# Crear diccionario de pesos de clase\n",
        "#class_weights = {0: 0.74, 1: 1.54}\n",
        "\n",
        "\n",
        "# Entrenar el model utilitzant generadors de dades\n",
        "#history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights)\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "#Ruta de l'arxiu on es guardarà el model\n",
        "ruta_model = os.path.join(drive_folder, \"model_CNN.h5\")\n",
        "\n",
        "# Guardar el model\n",
        "model.save(ruta_model)\n",
        "print(\"Model de la CNN guardat correctament.\")\n",
        "\n",
        "# Avaluar el model en el conjunt de prova utilitzant generador de dades\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Pèrdua en el conjunt de prova: {loss}\")\n",
        "print(f\"Precisió en el conjunt de prova: {accuracy}\")\n",
        "\n",
        "# Obtenir les prediccions del conjunt de prova\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertir les prediccions en etiquetes codificades\n",
        "y_pred_encoded = np.argmax(y_pred, axis=1)\n",
        "y_test_encoded = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calcular i mostrar la matriu de confussió\n",
        "confusion_mat = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
        "print(\"Matriu de confusió:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Calcular i mostrar l'informe de classificació\n",
        "classification_rep = classification_report(y_test_encoded, y_pred_encoded)\n",
        "print(\"Informe de classificació:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Calcular i mostrar la precisió\n",
        "precision = precision_score(y_test_encoded, y_pred_encoded)\n",
        "print(f\"Precisió: {precision}\")\n",
        "\n",
        "# Calcular i mostrar el recall\n",
        "recall = recall_score(y_test_encoded, y_pred_encoded)\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calcular i mostrar el F1-score\n",
        "f1 = f1_score(y_test_encoded, y_pred_encoded)\n",
        "print(f\"F1-score: {f1}\")\n",
        "\n",
        "# Calcular i mostrar l'exactitut (accuracy)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "print(f\"Exactitut: {accuracy}\")\n",
        "\n",
        "# Alliberar la memòria després d'avaluar el model\n",
        "del X_train, y_train, X_test, y_test\n",
        "gc.collect()  # Alliberar la memòria utilitzada per les variables eliminades"
      ],
      "metadata": {
        "id": "EiuZIZzyFliK",
        "outputId": "95f17717-623f-46cc-edf3-103fe45c71ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 11s 48ms/step - loss: 348.1213 - accuracy: 0.6369 - val_loss: 1.3536 - val_accuracy: 0.7286\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.6322 - accuracy: 0.8515 - val_loss: 0.3933 - val_accuracy: 0.8643\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3051 - accuracy: 0.8962 - val_loss: 0.3150 - val_accuracy: 0.8500\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.1797 - accuracy: 0.9195 - val_loss: 0.2890 - val_accuracy: 0.8786\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1576 - accuracy: 0.9356 - val_loss: 0.2680 - val_accuracy: 0.8857\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.3036 - val_accuracy: 0.8929\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.1134 - accuracy: 0.9571 - val_loss: 0.2601 - val_accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1051 - accuracy: 0.9624 - val_loss: 0.3088 - val_accuracy: 0.9071\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0918 - accuracy: 0.9714 - val_loss: 0.3129 - val_accuracy: 0.9143\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.2583 - val_accuracy: 0.9286\n",
            "Model de la CNN guardat correctament.\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2583 - accuracy: 0.9286\n",
            "Pèrdua en el conjunt de prova: 0.2582909166812897\n",
            "Precisió en el conjunt de prova: 0.9285714030265808\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Matriu de confusió:\n",
            "[[46  8]\n",
            " [ 2 84]]\n",
            "Informe de classificació:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90        54\n",
            "           1       0.91      0.98      0.94        86\n",
            "\n",
            "    accuracy                           0.93       140\n",
            "   macro avg       0.94      0.91      0.92       140\n",
            "weighted avg       0.93      0.93      0.93       140\n",
            "\n",
            "Precisió: 0.9130434782608695\n",
            "Recall: 0.9767441860465116\n",
            "F1-score: 0.9438202247191011\n",
            "Exactitut: 0.9285714285714286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1492"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}